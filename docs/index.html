<!doctype html>
<html lang="pt-BR">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width,initial-scale=1"/>
<title>Artigo — CIFAR-100 (Luciana Gouveia)</title>
<link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" rel="stylesheet">
<style>
  body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial; max-width:900px; margin:2rem auto; padding:0 1rem; color:#222; line-height:1.6 }
  h1,h2,h3 { font-weight:700 }
  pre { background:#f6f8fa; padding:1rem; overflow:auto }
  code { background:#f6f8fa; padding:0.15rem 0.3rem; border-radius:4px }
  img { max-width:100%; height:auto }
  .meta { color:#666; font-size:0.95rem }
  blockquote { color:#555; border-left:4px solid #ddd; padding:0.5rem 1rem }
</style>
</head>
<body>
<main>
<h1>Rascunho (polido) — EWMA, Otimizadores e Schedulers no CIFAR-100</h1>
<p><strong>Resumo</strong></p>
<p>Este texto sumariza os experimentos aplicados do Capítulo 6 (Deep Learning with PyTorch) ao CIFAR‑100. Abordamos: (i) o papel das médias móveis exponenciais (EWMA) na análise de gradientes; (ii) o funcionamento interno do Adam; (iii) comparações entre Adam, SGD (com e sem momentum) e Nesterov; (iv) LR range test e estratégias de <em>scheduling</em> de learning rate; (v) visualizações de mapas de ativação e gradientes.</p>
<p>O notebook reprodutível e os scripts estão no repositório: <code>notebooks/Cifar100.ipynb</code>. As figuras são servidas publicamente via GitHub Pages e, para garantir que o Medium importe corretamente as imagens, as links abaixo apontam para a URL pública do projeto.</p>
<hr />
<h2>Introdução</h2>
<p>Este trabalho objetiva esclarecer como suavizações (EWMA) e algoritmos adaptativos influenciam a dinâmica de treinamento em um problema de classificação com 100 classes (CIFAR‑100). As demonstrações são curtas e interpretativas — suficientes para ilustrar comportamento e permitir reprodução rápida; para resultados finais, execute mais épocas conforme indicado.</p>
<h2>Metodologia (resumo)</h2>
<ul>
<li>Arquitetura: LeNet‑like adaptado para CIFAR‑100 (implementação em <code>notebooks/Cifar100.ipynb</code>).</li>
<li>Ferramentas: PyTorch, torchvision, matplotlib, nbconvert.</li>
<li>Técnicas destacadas: EWMA (com e sem correção de viés), captura de gradientes via hooks, LR range test, StepLR / ReduceLROnPlateau / CyclicLR, visualização de mapas de ativação.</li>
</ul>
<h2>Configuração dos demos</h2>
<p>Parâmetros usados nas execuções curtas mostradas aqui:</p>
<ul>
<li><code>batch_size</code>: 128</li>
<li><code>num_epochs</code> (demos): 3</li>
<li><code>Adam lr</code>: 1e-3</li>
<li><code>SGD lr</code>: 1e-2</li>
<li><code>momentum</code>: 0.9</li>
<li><code>β₁</code> / <code>β₂</code> (Adam): 0.9 / 0.999</li>
<li>LR range test: 1e-6 → 1.0</li>
</ul>
<blockquote>
<p>Observação: os valores acima são para demonstração rápida; aumente <code>num_epochs</code> e batches para figuras finais.</p>
</blockquote>
<h2>Experimentos e figuras (para publicação)</h2>
<p>As imagens abaixo apontam para as versões públicas hospedadas via GitHub Pages (ex.: <code>https://LucianaGouv.github.io/pytorch-chapter6-cifar100/figures/&lt;nome&gt;.png</code>). Se for importar para o Medium, usar a URL pública na opção “Import a story” facilitará trazer as imagens automaticamente.</p>
<h4>Figura 1 — LR range test</h4>
<p><img alt="LR range test" src="https://LucianaGouv.github.io/pytorch-chapter6-cifar100/figures/lr_range_test.png" />
<strong>Legenda:</strong> Varredura de learning rate para identificar uma ordem de grandeza segura para iniciar o treino; o ponto onde a perda começa a decair indica bons candidatos para o LR.</p>
<h4>Figura 2 — Adam vs SGD (demo curto)</h4>
<p><img alt="Adam vs SGD" src="https://LucianaGouv.github.io/pytorch-chapter6-cifar100/figures/adam_vs_sgd_demo.png" />
<strong>Legenda:</strong> Comparação das curvas de perda (loss) em uma execução curta. Adam acelera a redução da perda no início; a comparação a longo prazo exige mais épocas.</p>
<h4>Figura 3 — Gradientes: brutos / EWMA / Adam-adapted</h4>
<p><img alt="Gradientes capture" src="https://LucianaGouv.github.io/pytorch-chapter6-cifar100/figures/gradients_capture_demo.png" />
<strong>Legenda:</strong> Gradientes brutos, suavisados por EWMA (β=0.9) e vetores adaptados utilizados pelo Adam. A EWMA mostra a tendência subjacente enquanto os adaptadores reescalam o passo por parâmetro.</p>
<h4>Figura 4 — Feature maps (todas as camadas)</h4>
<p><img alt="Feature maps" src="https://LucianaGouv.github.io/pytorch-chapter6-cifar100/figures/feature_maps_all_layers.png" />
<strong>Legenda:</strong> Mapas de ativação extraídos durante uma inferência — úteis para análise qualitativa de respostas de filtros.</p>
<h4>Figura 5 — Scheduler examples</h4>
<p><img alt="Schedulers" src="https://LucianaGouv.github.io/pytorch-chapter6-cifar100/figures/scheduler_examples.png" />
<strong>Legenda:</strong> Exemplos comparativos de políticas de redução de LR: <code>StepLR</code> vs <code>ReduceLROnPlateau</code>.</p>
<h4>Figura 6 — SGD Momentum vs Nesterov</h4>
<p><img alt="SGD vs Nesterov" src="https://LucianaGouv.github.io/pytorch-chapter6-cifar100/figures/sgd_nesterov_demo.png" />
<strong>Legenda:</strong> Comparação entre SGD+momentum e Nesterov (look-ahead). Em muitos casos Nesterov fornece uma resposta mais estável.</p>
<h2>Interpretações resumidas</h2>
<ul>
<li>EWMA é eficaz para reduzir ruído dos gradientes e, com correção de viés, produz estatísticas comparáveis às usadas por Adam.</li>
<li>Adam tende a convergir mais rápido nas fases iniciais; SGD + momentum / Nesterov pode alcançar melhores soluções em alguns cenários com ajuste de LR.</li>
<li>O LR range test é uma ferramenta prática para escolher a ordem de grandeza do LR inicial.</li>
</ul>
<h2>Reprodutibilidade</h2>
<ol>
<li>Clone o repositório e ative o virtualenv:</li>
</ol>
<div class="codehilite"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/LucianaGouv/pytorch-chapter6-cifar100.git
<span class="nb">cd</span><span class="w"> </span>pytorch-chapter6-cifar100
<span class="nb">source</span><span class="w"> </span>.venv/bin/activate
pip<span class="w"> </span>install<span class="w"> </span>-r<span class="w"> </span>requirements.txt
</code></pre></div>

<ol>
<li>Re-execute o notebook para regenerar as figuras (pode levar vários minutos):</li>
</ol>
<div class="codehilite"><pre><span></span><code>.venv/bin/python<span class="w"> </span>-m<span class="w"> </span>nbconvert<span class="w"> </span>--to<span class="w"> </span>notebook<span class="w"> </span>--execute<span class="w"> </span>--inplace<span class="w"> </span>notebooks/Cifar100.ipynb<span class="w"> </span>--ExecutePreprocessor.timeout<span class="o">=</span><span class="m">2400</span>
</code></pre></div>

<ol>
<li>
<p>O notebook e scripts principais:</p>
</li>
<li>
<p><code>notebooks/Cifar100.ipynb</code> — notebook executável (artefato primário)</p>
</li>
<li><code>experiments/Chapter6_CIFAR100_Complete.py</code> — script para execução completa</li>
<li><code>scripts/</code> — demos e utilitários (Nesterov demo, re-execução em alta-dpi, etc.)</li>
</ol>
<h2>Conclusão e próximos passos</h2>
<p>Este rascunho está pronto para publicação: recomendo importar via URL pública do GitHub Pages (ex.: <code>https://LucianaGouv.github.io/pytorch-chapter6-cifar100/</code>) para preservar imagens e formatação. Os próximos passos ideais antes da submissão final:</p>
<ul>
<li>Rodar experimentos completos (mais épocas) e substituir figuras por versões finais em <code>figures/</code>.</li>
<li>Revisar redação final e verificar referências/DOIs.</li>
<li>Publicar no Medium via "Import a story" usando a URL pública e revisar a versão importada.</li>
</ul>
<h2>Referências</h2>
<ul>
<li>Kingma, D. P. &amp; Ba, J., "Adam: A Method for Stochastic Optimization", ICLR 2015.</li>
<li>Goodfellow, Bengio, Courville — Deep Learning (capítulos relevantes).</li>
</ul>
<hr />
<p>Se quiser, eu posso (A) ajustar o texto para o tom do Medium (mais narrativo), (B) gerar uma versão com imagens embutidas inline no HTML para garantir import perfeito, ou (C) fazer a importação guiada no Medium passo a passo.</p>
</main>
<footer style="margin-top:2rem;color:#666;font-size:0.9rem">Gerado automaticamente a partir de `article/medium_draft.md`.</footer>
</body>
</html>
